{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"kapipy","text":"<p>A python client for accessing and querying datasets from geospatial open data portals such as LINZ, Stats NZ and LRIS.</p>"},{"location":"#overview","title":"Overview","text":"<p>kapipy is a Python package that provides a python interface to the Koordinates geospatial content management system. It allows users to connect to a data portal, retrieve metadata, and query vector layers and tables. </p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install kapipy\n</code></pre>"},{"location":"#basic-usage","title":"Basic Usage","text":"<ul> <li>Import kapipy.  </li> <li>Create a GIS object, passing in an api key.  </li> <li>Get a reference to an item using {gis}.content.get({layer_id})</li> <li>Perform actions on the item.  </li> </ul> <p>Basic example:  </p> <pre><code>from kapipy.gis import GIS\nlinz = GIS(name=\"linz\", api_key=\"my-linz-api-key\")\nrail_station_layer_id = \"50318\"\nitm = linz.content.get(rail_station_layer_id)\ndata = itm.query()\ndata.head()\n</code></pre>"},{"location":"#disclaimer","title":"Disclaimer","text":"<p>This is a hobby project and the modules are provided as-is on a best-effort basis. The author has no affiliation with either Koordinates nor LINZ, Stats NZ or LRIS. As such, the underlying API's and services may change at any time without warning and break these modules.  </p> <p>This project does not cover the full spectrum of the Koordinates API and probably never will. It focuses currently on basic workflows such as connecting using an api key, getting references to datasets and downloading them.  </p> <p>Suggestions and code contributions can be made by submitting issues via the GitHub page. </p>"},{"location":"about/","title":"How this came about","text":"<p>In New Zealand, where I am based, we are extremely lucky to have a wide range of open geospatial data available to us. One main source of this data is LINZ who provide an open data website with a wide range of data, including, for example, the cadastral datasets. Their website has a great UI for exploring and exporting data, as well as instructions for loading web services directly into desktop applications.  </p> <p>I work a lot with local councils and other organisations wanting to use data from LINZ within ETL processes using python. Over the years, I have seen (and written!) various implementations of python scripts that query the LINZ data API's and download data. Usually these are some variation of sending requests to the WFS endpoint. A particular use case is to download changeset data to keep local data up to date. The local data is then mashed up with internal datasets, such as rating information, to create various derived outputs.  </p> <p>My role as a GIS Advisor is primarily within the ArcGIS eco-system, and as such I work a lot with the ArcGIS API for Python. This is a comprehensive python package provided by Esri to interact with the ArcGIS data portals: ArcGIS Online and ArcGIS Enterprise.  </p> <p>I wrote and re-wrote several LINZ export helper scripts, and eventually I realised that I wanted to provide a familiar experience for extracting data from LINZ, with similarities to how the ArcGIS API for Python package allows to browse ArcGIS portal content.  </p> <p>The general approach is: - Get a reference to a portal. - Get a reference to a content item from that portal. - Perform actions on that content.  </p> <p>To me, this feels like a natural way to interact with a data portal. The export API's provide the data as a zip file download. The query and changeset features retrieve raw json data, which can be returned as either a geopandas GeoDataFrame or the ArcGIS Spatially Enabled DataFrame. This makes it useful to all users, but extra convenient for ArcGIS users who will may already be using sdf inside scripts. In fact, I find myself using kapipy within Jupyter and ArcGIS Notebooks as I can now bring in and display data layers from both LINZ and ArcGIS portals using a similar approach.   </p> <p>As a bonus, this was the first time I had attempted building a python package and publishing to PyPi. Constructing a package like this is a great way to learn, as it forces you to think about software architecture. Already I have re-organised the modules and components several times!</p> <p>For example, after the AI overlords helped me implement a JobResult class, I initially kept a list attribute with the item class and added the job object to that list. I thought that would enable the user to retrospectively review and redownload prior jobs. But then I changed my mind. How often would a user create multiple download jobs for the same item within the same run of a script? There seemed little utility for the job list. Then it occurred to me that keeping a more overarching jobs list with the ContentManager might be more useful. If the ContentManager controlled the exports and kept a list of them, I could envisage a workflow where a script generated export requests for several items, then one call to the ContentManager export method could download them all to a folder in one go.  </p> <p>Your use cases may differ. Feel free to contribute ideas, feedback and code via the GitHub repo.  </p> <pre><code>*|********\n*|*/******\n*|/**|\\***\n*|\\**|*\\**\n*|*\\*|*/**\n*****|/***\n*****|****\n*****|****\n</code></pre>"},{"location":"development_notes/","title":"Development Notes","text":"<p>These are just general notes for the author to help remember design choices, rabbit holes and how they panned out, etc.  </p>"},{"location":"development_notes/#installation","title":"Installation","text":"<p>When I run <code>uv sync</code> and <code>uv pip install -e .</code> on a new cloned copy, if I have a python environment activated already in my terminal it seems to do odd things sometimes. VS Code sometimes activates automatically depending on settings. And sometimes those settings vary between PowerShell and the standard Command Prompt. So I find it best to ensure I open a separate Command Prompt window with nothing activated, run those initial commands there, and then open up VS Code and any terminal windows. </p> <p>If installing from the whl file using UV, remember to add the package name.</p> <pre><code>uv pip install kapipy@path/to/packagefile.whl\n</code></pre> <p>If using the code directly rather than installing from PyPi (once it is uploaded to there), run the following to install the package locally in editable mode.</p> <pre><code>pip install -e .\n</code></pre>"},{"location":"development_notes/#arcgis","title":"ArcGIS","text":"<p>Recommend using the existing conda manager that comes installed with ArcGIS Pro or ArcGIS Server. If using arcgis module but not arcpy installed, need to install: - pyproj - shapely - pyshp</p> <p>Optionally pip install dotenv if wanting to use that. If creating a blank conda environment (rather than cloning the default), and wanting to use Jupyter notebooks, install: - ipykernel - ptyprocess - comm</p> <p>When converting geojson to sdf, I first tried using FeatureSet.from_geojson(geojson) but I found that it assumes that the geojson is in wgs84 (which is the strict definition of geojson). But in our case sometimes we often get the geojson returned already in NZTM/2193. So the from_geojson ended up with incorrect spatial data.  So I write a function that manually converts the geojson to an ArcGIS FeatureSet by passing in the json, fields and wkid. Then I can convert that FeatureSet to an sdf.  </p>"},{"location":"development_notes/#development-using-jupyter-notebooks","title":"Development using Jupyter Notebooks","text":"<p>I got the following tips from Cookie Cutter Data Science. Cookie Cutter Data Science </p> <p>Make the project a python package and install it locally. I was using UV, so I ran this command:</p> <pre><code>uv pip install -e .  \n</code></pre> <p>Then, in my notebook, I included this cell first:  </p> <pre><code>%load_ext autoreload\n%autoreload 2\n</code></pre> <p>This allowed me to load my local python package like this:  </p> <pre><code>from k_data_helpers import KServer  \n</code></pre> <p>And it would hot reload any changes I made while developing.</p>"},{"location":"development_notes/#koordinates-api","title":"Koordinates API","text":""},{"location":"development_notes/#export-api","title":"Export API","text":"<p>The export api doesn't appear to have an option for applying a cql_filter or any similar filter. Only extent. The extent appears to have to be a geojson geometry object. Note that this is just the geometry part, not the properties or collection. And it would have to be in WGS84. I might look at ways to handle passing in geometry objects of different types, such as from a geopandas geometry, and behind the scenes just handling that and converting to the corrrect format.  </p> <p>Also, the export API treats the extent as a crop, and so features will be clipped. This may not be desired in all situations, e.g. clipping Property Parcels is not usually a good thing as someone may inadvertantly think that that is the actually parcel geometry, not realising it was clipped. The question is: how to handle this? Just warn the user in documentation and leave it up to them? Apply a buffer and do some post-processing? I'm inclined to do less, let the system supply as it is designed, and educate the user. This does imply the end user needs to do a little bit extra work but I would rather the user explicitly get the output and the module logic not get in the way.  </p> <p>It does appear to allow generating an export of multiple items at once. E.g. you could request several layers in one zipped file geodatabase. Currently, this wrapper only supports one at a time, because I didn't realise at the time you could do multiple, so this would be a good enhancement for the future. The current approach is based off starting with an item and downloading that. So a multi item download would need to be initiated by a higher order class, perhaps the ContentManager?  </p> <p>Need to think about how a user would most likely pass in the parameters for a multi download without constructing the whole list verbosely, but allowing them to do that if they wish.  </p>"},{"location":"development_notes/#notes-on-design-choices","title":"Notes on design choices","text":""},{"location":"development_notes/#owslib","title":"OWSLib","text":"<p>I investigated using the OWSLib python package to download the WFS data, but discovered that it doesn't support the CQL filter keyword option that the LINZ GeoServer provides. OGC filters were still an option, but seem very complex to construct and I believe most users would prefer to use the simpler CQL which is more similar to SQL. So I moved back to using a basic request to the WFS endpoint. The OWSLib package would provide more scope for expansion, but since the intent of this helper library is primarily focused on Koordinates and LINZ in particular, we can afford to be a little more opinionated on our approach, such as not having to support all the WFS versions. I'm not sure if the LINZ WFS endpoint is strictly equivalent with all other Koordinates WFS endpoints. So the implementation at the moment is coded to work with LINZ and might not work in other places.  </p>"},{"location":"development_notes/#prompts","title":"Prompts","text":"<p>Can you review the docstrings for all classes, methods and functions. Make sure they are accurate and reflect the correct Parameters and Return values. Ensure the syntax is correct, use the word Parameters instead of Args, and ensure the formatting is consistent for use with MkDocs and the Google format. Only provide docstrings that actually need to change. Provide each docstring in a separate section so I can copy and paste it. There is no need to provide the original for comparison. Provide an update for str and repr if necessary. Check that the type hints are accurate.</p>"},{"location":"development_notes/#tests","title":"Tests","text":"<p>Tests are written using pytest.</p> <p>To run all tests with logging. Leave off the log parameter if not wanting logging.  </p> <pre><code>uv run -m pytest --log-cli-level=INFO\n</code></pre> <p>To run a specific test, replace the relevant file name and test function.  </p> <pre><code>uv run -m pytest tests/test_simple.py::test_validate_layer_export_params --log-cli-level=INFO\n</code></pre> <p>There is currently very limited test coverage. Any live tests require a \"LINZ_API_KEY\" entry to exist in a .env file in the root project folder.  </p>"},{"location":"development_notes/#data-classes","title":"Data Classes","text":"<p>BaseItem</p> <p>LayerItem</p> <p>Group</p> <p>Publisher</p> <p>Theme</p> <p>Site</p> <p>DataDetails</p> <p>Fields</p> <p>Crs</p> <p>Extent</p> <p>ChangeSummary</p> <p>ImportLog</p> <p>ExportFormat</p> <p>Category</p> <p>Ancestor</p> <p>Item required fields:</p> <p>class BaseItem(Protocol):     id     url     type_     title     description     data     kind     categories     tags     created_at     license     metadata     num_views     num_downloads</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"faq/#is-this-a-comprehensive-python-wrapper-for-the-koordinates-api","title":"Is this a comprehensive python wrapper for the Koordinates API?","text":"<p>No. The focus here is primarily on extracting data easily, and it is unlikely to ever move beyond data exploration and export. The project is young, and even within the that narrow scope there is more can be done. At the time of writing, only Vector and Table datasets are implemented, as it felt like those are the core datasets that might require regular downloading.</p>"},{"location":"faq/#how-do-i-get-an-api-key","title":"How do I get an API key?","text":"<p>LINZ, Stats NZ and LRIS all have sign up pages. They should be a common Koordinates login, but you need to generate separate API keys from each site separately.  </p>"},{"location":"faq/#how-do-i-report-bugs-or-provide-feedback","title":"How do I report bugs or provide feedback?","text":"<p>The recommended way is via the GitHub issues page.  .  </p>"},{"location":"faq/#will-it-work-with-other-koordinates-data-portals","title":"Will it work with other Koordinates data portals?","text":"<p>Probably? Maybe? Not sure. Try it and provide feedback if it doesn't! The focus during development is purely on LINZ, Stats NZ and LRIS, so those are the only ones that have been tested.  </p>"},{"location":"reference/","title":"API Reference","text":""},{"location":"reference/#kapipy.gis.GIS","title":"GIS","text":"<pre><code>GIS(\n    name=None,\n    url=None,\n    api_key=None,\n    api_version=DEFAULT_API_VERSION,\n)\n</code></pre> <p>Client for connecting to a Koordinates server.</p> <p>Provides methods for authenticating, accessing content, and making HTTP requests to the Koordinates API. Used as the main entry point for interacting with Koordinates-hosted data.</p> <p>Attributes:</p> <ul> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>The name of the Koordinates portal. If this is provided, the url is ignored.  </p> </li> <li> <code>url</code>               (<code>str</code>)           \u2013            <p>The base URL of the Koordinates server.</p> </li> <li> <code>_api_version</code>               (<code>str</code>)           \u2013            <p>The API version to use.</p> </li> <li> <code>_content_manager</code>               (<code>ContentManager or None</code>)           \u2013            <p>Cached ContentManager instance.</p> </li> <li> <code>_api_key</code>               (<code>str</code>)           \u2013            <p>The API key for authenticating requests.</p> </li> </ul> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the portal name is not recognized or if api_key is not provided.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>get</code>             \u2013              <p>Makes a synchronous GET request to the specified URL with the provided parameters.</p> </li> <li> <code>reset</code>             \u2013              <p>Resets the GIS instance. </p> </li> </ul>"},{"location":"reference/#kapipy.gis.GIS(name)","title":"<code>name</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The name of the Koordinates portal (e.g., 'linz'). If provided, overrides url.</p>"},{"location":"reference/#kapipy.gis.GIS(url)","title":"<code>url</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The base URL of the Koordinates server. Used if name is not provided.</p>"},{"location":"reference/#kapipy.gis.GIS(api_key)","title":"<code>api_key</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The API key for authenticating with the Koordinates server.</p>"},{"location":"reference/#kapipy.gis.GIS(api_version)","title":"<code>api_version</code>","text":"(<code>str</code>, default:                   <code>DEFAULT_API_VERSION</code> )           \u2013            <p>The API version to use. Defaults to 'v1.x'.</p>"},{"location":"reference/#kapipy.gis.GIS.content","title":"content  <code>property</code>","text":"<pre><code>content: ContentManager\n</code></pre> <p>Returns the ContentManager instance for this server.</p> <p>Returns:</p> <ul> <li> <code>ContentManager</code> (              <code>ContentManager</code> )          \u2013            <p>The content manager associated with this server.</p> </li> </ul>"},{"location":"reference/#kapipy.gis.GIS.get","title":"get","text":"<pre><code>get(url: str, params: dict = None) -&gt; dict\n</code></pre> <p>Makes a synchronous GET request to the specified URL with the provided parameters. Injects the API key into the request headers.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict</code> (              <code>dict</code> )          \u2013            <p>The JSON-decoded response from the server.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>BadRequest</code>             \u2013            <p>If the request fails with a 400 status code.</p> </li> <li> <code>ServerError</code>             \u2013            <p>For other HTTP errors or request exceptions.</p> </li> </ul>"},{"location":"reference/#kapipy.gis.GIS.get(url)","title":"<code>url</code>","text":"(<code>str</code>)           \u2013            <p>The URL to send the GET request to.</p>"},{"location":"reference/#kapipy.gis.GIS.get(params)","title":"<code>params</code>","text":"(<code>dict</code>, default:                   <code>None</code> )           \u2013            <p>Query parameters to include in the request. Defaults to None.</p>"},{"location":"reference/#kapipy.gis.GIS.reset","title":"reset","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Resets the GIS instance.  This is useful if the API key or other configurations change.</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul>"},{"location":"reference/#kapipy.content_manager.ContentManager","title":"ContentManager","text":"<pre><code>ContentManager(gis: GIS)\n</code></pre> <p>Manages content for a GIS instance.</p> <p>Provides methods to search for, retrieve, and instantiate Koordinates items (layers, tables, etc.) based on their IDs or URLs.</p> <p>Attributes:</p> <ul> <li> <code>_gis</code>               (<code>GIS</code>)           \u2013            <p>The GIS instance this manager is associated with.</p> </li> </ul> <p>Parameters:</p> <ul> <li> </li> </ul> <p>Methods:</p> <ul> <li> <code>download</code>             \u2013              <p>Downloads all exports from a list of jobs.</p> </li> <li> <code>export</code>             \u2013              <p>Exports the item in the specified format.</p> </li> <li> <code>get</code>             \u2013              <p>Retrieves and instantiates a content item by ID from the GIS.</p> </li> </ul>"},{"location":"reference/#kapipy.content_manager.ContentManager(gis)","title":"<code>gis</code>","text":"(<code>GIS</code>)           \u2013            <p>The GIS instance to manage content for.</p>"},{"location":"reference/#kapipy.content_manager.ContentManager.download","title":"download","text":"<pre><code>download(\n    jobs: list[JobResults] = None,\n    folder: str = None,\n    poll_interval: int = 10,\n    force_all: bool = False,\n) -&gt; list[JobResults]\n</code></pre> <p>Downloads all exports from a list of jobs. Polls the jobs until they are finished. As soon as it encounters a finished job, it pauses polling and downloads that file, then resumes polling the remainder.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[JobResults]</code>           \u2013            <p>list[JobResult]: The list of job result objects after download.</p> </li> </ul>"},{"location":"reference/#kapipy.content_manager.ContentManager.download(jobs)","title":"<code>jobs</code>","text":"(<code>list[JobResult]</code>, default:                   <code>None</code> )           \u2013            <p>The list of job result objects to download.</p>"},{"location":"reference/#kapipy.content_manager.ContentManager.download(folder)","title":"<code>folder</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The output folder where files will be saved.</p>"},{"location":"reference/#kapipy.content_manager.ContentManager.download(poll_interval)","title":"<code>poll_interval</code>","text":"(<code>int</code>, default:                   <code>10</code> )           \u2013            <p>The interval in seconds to poll the jobs. Default is 10.</p>"},{"location":"reference/#kapipy.content_manager.ContentManager.export","title":"export","text":"<pre><code>export(\n    itm: BaseItem,\n    export_format: str,\n    wkid: Optional[int] = None,\n    extent: Optional[\n        Union[dict, GeoDataFrame, DataFrame]\n    ] = None,\n    poll_interval: int = 10,\n    timeout: int = 600,\n    **kwargs: Any,\n) -&gt; JobResult\n</code></pre> <p>Exports the item in the specified format.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>JobResult</code> (              <code>JobResult</code> )          \u2013            <p>A JobResult instance containing the export job details.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If export validation fails.</p> </li> </ul>"},{"location":"reference/#kapipy.content_manager.ContentManager.export(export_format)","title":"<code>export_format</code>","text":"(<code>str</code>)           \u2013            <p>The format to export the item in.</p>"},{"location":"reference/#kapipy.content_manager.ContentManager.export(wkid)","title":"<code>wkid</code>","text":"(<code>int</code>, default:                   <code>None</code> )           \u2013            <p>The coordinate reference system code to use for the export.</p>"},{"location":"reference/#kapipy.content_manager.ContentManager.export(extent)","title":"<code>extent</code>","text":"(<code>dict or GeoDataFrame or DataFrame</code>, default:                   <code>None</code> )           \u2013            <p>The extent to use for the export. Should be a GeoJSON dictionary, GeoDataFrame, or SEDF.</p>"},{"location":"reference/#kapipy.content_manager.ContentManager.export(poll_interval)","title":"<code>poll_interval</code>","text":"(<code>int</code>, default:                   <code>10</code> )           \u2013            <p>The interval in seconds to poll the export job status. Default is 10 seconds.</p>"},{"location":"reference/#kapipy.content_manager.ContentManager.export(timeout)","title":"<code>timeout</code>","text":"(<code>int</code>, default:                   <code>600</code> )           \u2013            <p>The maximum time in seconds to wait for the export job to complete. Default is 600 seconds (10 minutes).</p>"},{"location":"reference/#kapipy.content_manager.ContentManager.export(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional parameters for the export request.</p>"},{"location":"reference/#kapipy.content_manager.ContentManager.get","title":"get","text":"<pre><code>get(id: str) -&gt; dict\n</code></pre> <p>Retrieves and instantiates a content item by ID from the GIS.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict</code>           \u2013            <p>VectorItem or TableItem or None: The instantiated item, depending on its kind, or None if not found.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>BadRequest</code>             \u2013            <p>If the content is not found or the request is invalid.</p> </li> <li> <code>UnknownItemTypeError</code>             \u2013            <p>If the item kind is not supported.</p> </li> <li> <code>ServerError</code>             \u2013            <p>If the item does not have a URL.</p> </li> </ul>"},{"location":"reference/#kapipy.content_manager.ContentManager.get(id)","title":"<code>id</code>","text":"(<code>str</code>)           \u2013            <p>The ID of the content to retrieve.</p>"},{"location":"reference/#kapipy.items.VectorItem","title":"VectorItem  <code>dataclass</code>","text":"<pre><code>VectorItem(\n    id: int,\n    url: str,\n    type_: str,\n    title: str,\n    description: str,\n    data: VectorItemData,\n    services: str,\n    kind: str,\n    categories: List[Any],\n    tags: List[str],\n    created_at: str,\n    license: Any,\n    metadata: Any,\n    num_views: int,\n    num_downloads: int,\n)\n</code></pre> <p>               Bases: <code>BaseItem</code>, <code>WFS</code></p> <p>Methods:</p> <ul> <li> <code>changeset</code>             \u2013              <p>Retrieves a changeset for the item and returns it as a GeoDataFrame, SEDF, or JSON.</p> </li> <li> <code>changeset_to_json</code>             \u2013              <p>Retrieves a changeset for the item in JSON format.</p> </li> <li> <code>export</code>             \u2013              <p>Exports the item in the specified format.</p> </li> <li> <code>query</code>             \u2013              <p>Executes a WFS query on the item and returns the result as a GeoDataFrame, SEDF, or JSON.</p> </li> <li> <code>query_to_json</code>             \u2013              <p>Executes a WFS query on the item and returns the result as JSON.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>supports_changesets</code>               (<code>bool</code>)           \u2013            <p>Returns whether the item supports changesets.</p> </li> </ul>"},{"location":"reference/#kapipy.items.VectorItem.supports_changesets","title":"supports_changesets  <code>property</code>","text":"<pre><code>supports_changesets: bool\n</code></pre> <p>Returns whether the item supports changesets.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the item supports changesets, False otherwise.</p> </li> </ul>"},{"location":"reference/#kapipy.items.VectorItem.changeset","title":"changeset","text":"<pre><code>changeset(\n    from_time: str,\n    to_time: str = None,\n    out_sr: int = None,\n    cql_filter: str = None,\n    bbox: Union[str, GeoDataFrame, DataFrame] = None,\n    output_format=None,\n    **kwargs: Any,\n) -&gt; GeoDataFrame\n</code></pre> <p>Retrieves a changeset for the item and returns it as a GeoDataFrame, SEDF, or JSON.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame</code>           \u2013            <p>gpd.GeoDataFrame or arcgis.features.GeoAccessor or dict: The changeset data as a GeoDataFrame, SEDF, or JSON.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ImportError</code>             \u2013            <p>If the requested output format requires a package that is not installed.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If the output format is unknown.</p> </li> </ul>"},{"location":"reference/#kapipy.items.VectorItem.changeset(from_time)","title":"<code>from_time</code>","text":"(<code>str</code>)           \u2013            <p>The start time for the changeset query, ISO format (e.g., \"2015-05-15T04:25:25.334974\").</p>"},{"location":"reference/#kapipy.items.VectorItem.changeset(to_time)","title":"<code>to_time</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The end time for the changeset query, ISO format. If not provided, the current time is used.</p>"},{"location":"reference/#kapipy.items.VectorItem.changeset(out_sr)","title":"<code>out_sr</code>","text":"(<code>int</code>, default:                   <code>None</code> )           \u2013            <p>The spatial reference system code to use for the query.</p>"},{"location":"reference/#kapipy.items.VectorItem.changeset(cql_filter)","title":"<code>cql_filter</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The CQL filter to apply to the changeset query.</p>"},{"location":"reference/#kapipy.items.VectorItem.changeset(bbox)","title":"<code>bbox</code>","text":"(<code>str or GeoDataFrame or DataFrame</code>, default:                   <code>None</code> )           \u2013            <p>The bounding box to apply to the changeset query. If a GeoDataFrame or SEDF is provided, it will be converted to a bounding box string in WGS84.</p>"},{"location":"reference/#kapipy.items.VectorItem.changeset(output_format)","title":"<code>output_format</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The output format: 'gdf', 'sdf', or 'json'. Defaults to the best available.</p>"},{"location":"reference/#kapipy.items.VectorItem.changeset(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional parameters for the WFS query.</p>"},{"location":"reference/#kapipy.items.VectorItem.changeset_to_json","title":"changeset_to_json","text":"<pre><code>changeset_to_json(\n    from_time: str,\n    to_time: str = None,\n    out_sr=None,\n    cql_filter: str = None,\n    bbox: Union[str, GeoDataFrame, DataFrame] = None,\n    **kwargs: Any,\n) -&gt; dict\n</code></pre> <p>Retrieves a changeset for the item in JSON format.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict</code> (              <code>dict</code> )          \u2013            <p>The changeset data in JSON format.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the item does not support changesets.</p> </li> </ul>"},{"location":"reference/#kapipy.items.VectorItem.changeset_to_json(from_time)","title":"<code>from_time</code>","text":"(<code>str</code>)           \u2013            <p>The start time for the changeset query, ISO format (e.g., \"2015-05-15T04:25:25.334974\").</p>"},{"location":"reference/#kapipy.items.VectorItem.changeset_to_json(to_time)","title":"<code>to_time</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The end time for the changeset query, ISO format. If not provided, the current time is used.</p>"},{"location":"reference/#kapipy.items.VectorItem.changeset_to_json(cql_filter)","title":"<code>cql_filter</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The CQL filter to apply to the changeset query.</p>"},{"location":"reference/#kapipy.items.VectorItem.changeset_to_json(bbox)","title":"<code>bbox</code>","text":"(<code>str or GeoDataFrame</code>, default:                   <code>None</code> )           \u2013            <p>The bounding box to apply to the changeset query. If a GeoDataFrame is provided, it will be converted to a bounding box string in WGS84.</p>"},{"location":"reference/#kapipy.items.VectorItem.changeset_to_json(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional parameters for the WFS query.</p>"},{"location":"reference/#kapipy.items.VectorItem.export","title":"export","text":"<pre><code>export(\n    export_format: str,\n    out_sr: int = None,\n    extent: Union[dict, GeoDataFrame, DataFrame] = None,\n    poll_interval: int = None,\n    timeout: int = None,\n    **kwargs: Any,\n) -&gt; JobResult\n</code></pre> <p>Exports the item in the specified format.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>JobResult</code> (              <code>JobResult</code> )          \u2013            <p>A JobResult instance containing the export job details.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If export validation fails.</p> </li> </ul>"},{"location":"reference/#kapipy.items.VectorItem.export(export_format)","title":"<code>export_format</code>","text":"(<code>str</code>)           \u2013            <p>The format to export the item in.</p>"},{"location":"reference/#kapipy.items.VectorItem.export(out_sr)","title":"<code>out_sr</code>","text":"(<code>int</code>, default:                   <code>None</code> )           \u2013            <p>The coordinate reference system code to use for the export.</p>"},{"location":"reference/#kapipy.items.VectorItem.export(extent)","title":"<code>extent</code>","text":"(<code>dict or GeoDataFrame or DataFrame</code>, default:                   <code>None</code> )           \u2013            <p>The extent to use for the export. Should be a GeoJSON dictionary, GeoDataFrame, or SEDF.</p>"},{"location":"reference/#kapipy.items.VectorItem.export(poll_interval)","title":"<code>poll_interval</code>","text":"(<code>int</code>, default:                   <code>None</code> )           \u2013            <p>The interval in seconds to poll the export job status. Default is 10 seconds.</p>"},{"location":"reference/#kapipy.items.VectorItem.export(timeout)","title":"<code>timeout</code>","text":"(<code>int</code>, default:                   <code>None</code> )           \u2013            <p>The maximum time in seconds to wait for the export job to complete. Default is 600 seconds (10 minutes).</p>"},{"location":"reference/#kapipy.items.VectorItem.export(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional parameters for the export request.</p>"},{"location":"reference/#kapipy.items.VectorItem.query","title":"query","text":"<pre><code>query(\n    cql_filter: str = None,\n    out_sr: int = None,\n    bbox: Union[str, GeoDataFrame, DataFrame] = None,\n    output_format=None,\n    **kwargs: Any,\n) -&gt; GeoDataFrame\n</code></pre> <p>Executes a WFS query on the item and returns the result as a GeoDataFrame, SEDF, or JSON.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame</code>           \u2013            <p>gpd.GeoDataFrame or arcgis.features.GeoAccessor or dict: The result of the WFS query as a GeoDataFrame, SEDF, or JSON.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ImportError</code>             \u2013            <p>If the requested output format requires a package that is not installed.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If the output format is unknown.</p> </li> </ul>"},{"location":"reference/#kapipy.items.VectorItem.query(cql_filter)","title":"<code>cql_filter</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The CQL filter to apply to the query.</p>"},{"location":"reference/#kapipy.items.VectorItem.query(out_sr)","title":"<code>out_sr</code>","text":"(<code>int</code>, default:                   <code>None</code> )           \u2013            <p>The spatial reference system code to use for the query.</p>"},{"location":"reference/#kapipy.items.VectorItem.query(bbox)","title":"<code>bbox</code>","text":"(<code>str or GeoDataFrame or DataFrame</code>, default:                   <code>None</code> )           \u2013            <p>The bounding box to apply to the query. If a GeoDataFrame or SEDF is provided, it will be converted to a bounding box string in WGS84.</p>"},{"location":"reference/#kapipy.items.VectorItem.query(output_format)","title":"<code>output_format</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The output format: 'gdf', 'sdf', or 'json'. Defaults to the best available.</p>"},{"location":"reference/#kapipy.items.VectorItem.query(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional parameters for the WFS query.</p>"},{"location":"reference/#kapipy.items.VectorItem.query_to_json","title":"query_to_json","text":"<pre><code>query_to_json(\n    cql_filter: str = None,\n    out_sr: int = None,\n    bbox: Union[str, GeoDataFrame, DataFrame] = None,\n    **kwargs: Any,\n) -&gt; dict\n</code></pre> <p>Executes a WFS query on the item and returns the result as JSON.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict</code> (              <code>dict</code> )          \u2013            <p>The result of the WFS query in JSON format.</p> </li> </ul>"},{"location":"reference/#kapipy.items.VectorItem.query_to_json(cql_filter)","title":"<code>cql_filter</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The CQL filter to apply to the query.</p>"},{"location":"reference/#kapipy.items.VectorItem.query_to_json(out_sr)","title":"<code>out_sr</code>","text":"(<code>int</code>, default:                   <code>None</code> )           \u2013            <p>The spatial reference system code to use for the query.</p>"},{"location":"reference/#kapipy.items.VectorItem.query_to_json(bbox)","title":"<code>bbox</code>","text":"(<code>str or GeoDataFrame or DataFrame</code>, default:                   <code>None</code> )           \u2013            <p>The bounding box to apply to the query. If a GeoDataFrame or SEDF is provided, it will be converted to a bounding box string in WGS84.</p>"},{"location":"reference/#kapipy.items.VectorItem.query_to_json(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional parameters for the WFS query.</p>"},{"location":"reference/#kapipy.items.TableItem","title":"TableItem  <code>dataclass</code>","text":"<pre><code>TableItem(\n    id: int,\n    url: str,\n    type_: str,\n    title: str,\n    description: str,\n    data: ItemData,\n    services: str,\n    kind: str,\n    categories: List[Any],\n    tags: List[str],\n    created_at: str,\n    license: Any,\n    metadata: Any,\n    num_views: int,\n    num_downloads: int,\n)\n</code></pre> <p>               Bases: <code>BaseItem</code>, <code>WFS</code></p> <p>Methods:</p> <ul> <li> <code>export</code>             \u2013              <p>Exports the item in the specified format.</p> </li> <li> <code>get_changeset</code>             \u2013              <p>Retrieves a changeset for the item and returns it as a DataFrame.</p> </li> <li> <code>get_changeset_json</code>             \u2013              <p>Retrieves a changeset for the item in JSON format.</p> </li> <li> <code>query</code>             \u2013              <p>Executes a WFS query on the item and returns the result as a DataFrame.</p> </li> <li> <code>query_json</code>             \u2013              <p>Executes a WFS query on the item and returns the result as JSON.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>supports_changesets</code>               (<code>bool</code>)           \u2013            <p>Returns whether the item supports changesets.</p> </li> </ul>"},{"location":"reference/#kapipy.items.TableItem.supports_changesets","title":"supports_changesets  <code>property</code>","text":"<pre><code>supports_changesets: bool\n</code></pre> <p>Returns whether the item supports changesets.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the item supports changesets, False otherwise.</p> </li> </ul>"},{"location":"reference/#kapipy.items.TableItem.export","title":"export","text":"<pre><code>export(\n    export_format: str,\n    poll_interval: int = None,\n    timeout: int = None,\n    **kwargs: Any,\n) -&gt; JobResult\n</code></pre> <p>Exports the item in the specified format.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>JobResult</code> (              <code>JobResult</code> )          \u2013            <p>A JobResult instance containing the export job details.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If export validation fails.</p> </li> </ul>"},{"location":"reference/#kapipy.items.TableItem.export(export_format)","title":"<code>export_format</code>","text":"(<code>str</code>)           \u2013            <p>The format to export the item in.</p>"},{"location":"reference/#kapipy.items.TableItem.export(poll_interval)","title":"<code>poll_interval</code>","text":"(<code>int</code>, default:                   <code>None</code> )           \u2013            <p>The interval in seconds to poll the export job status. Default is 10 seconds.</p>"},{"location":"reference/#kapipy.items.TableItem.export(timeout)","title":"<code>timeout</code>","text":"(<code>int</code>, default:                   <code>None</code> )           \u2013            <p>The maximum time in seconds to wait for the export job to complete. Default is 600 seconds (10 minutes).</p>"},{"location":"reference/#kapipy.items.TableItem.export(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional parameters for the export request.</p>"},{"location":"reference/#kapipy.items.TableItem.get_changeset","title":"get_changeset","text":"<pre><code>get_changeset(\n    from_time: str,\n    to_time: str = None,\n    cql_filter: str = None,\n    **kwargs: Any,\n) -&gt; dict\n</code></pre> <p>Retrieves a changeset for the item and returns it as a DataFrame.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict</code>           \u2013            <p>pandas.DataFrame: The changeset data as a DataFrame.</p> </li> </ul>"},{"location":"reference/#kapipy.items.TableItem.get_changeset(from_time)","title":"<code>from_time</code>","text":"(<code>str</code>)           \u2013            <p>The start time for the changeset query, ISO format (e.g., \"2015-05-15T04:25:25.334974\").</p>"},{"location":"reference/#kapipy.items.TableItem.get_changeset(to_time)","title":"<code>to_time</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The end time for the changeset query, ISO format. If not provided, the current time is used.</p>"},{"location":"reference/#kapipy.items.TableItem.get_changeset(cql_filter)","title":"<code>cql_filter</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The CQL filter to apply to the changeset query.</p>"},{"location":"reference/#kapipy.items.TableItem.get_changeset(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional parameters for the WFS query.</p>"},{"location":"reference/#kapipy.items.TableItem.get_changeset_json","title":"get_changeset_json","text":"<pre><code>get_changeset_json(\n    from_time: str,\n    to_time: str = None,\n    cql_filter: str = None,\n    **kwargs: Any,\n) -&gt; dict\n</code></pre> <p>Retrieves a changeset for the item in JSON format.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict</code> (              <code>dict</code> )          \u2013            <p>The changeset data in JSON format.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the item does not support changesets.</p> </li> </ul>"},{"location":"reference/#kapipy.items.TableItem.get_changeset_json(from_time)","title":"<code>from_time</code>","text":"(<code>str</code>)           \u2013            <p>The start time for the changeset query, ISO format (e.g., \"2015-05-15T04:25:25.334974\").</p>"},{"location":"reference/#kapipy.items.TableItem.get_changeset_json(to_time)","title":"<code>to_time</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The end time for the changeset query, ISO format. If not provided, the current time is used.</p>"},{"location":"reference/#kapipy.items.TableItem.get_changeset_json(cql_filter)","title":"<code>cql_filter</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The CQL filter to apply to the changeset query.</p>"},{"location":"reference/#kapipy.items.TableItem.get_changeset_json(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional parameters for the WFS query.</p>"},{"location":"reference/#kapipy.items.TableItem.query","title":"query","text":"<pre><code>query(cql_filter: str = None, **kwargs: Any) -&gt; dict\n</code></pre> <p>Executes a WFS query on the item and returns the result as a DataFrame.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict</code>           \u2013            <p>pandas.DataFrame: The result of the WFS query as a DataFrame.</p> </li> </ul>"},{"location":"reference/#kapipy.items.TableItem.query(cql_filter)","title":"<code>cql_filter</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The CQL filter to apply to the query.</p>"},{"location":"reference/#kapipy.items.TableItem.query(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional parameters for the WFS query.</p>"},{"location":"reference/#kapipy.items.TableItem.query_json","title":"query_json","text":"<pre><code>query_json(cql_filter: str = None, **kwargs: Any) -&gt; dict\n</code></pre> <p>Executes a WFS query on the item and returns the result as JSON.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict</code> (              <code>dict</code> )          \u2013            <p>The result of the WFS query in JSON format.</p> </li> </ul>"},{"location":"reference/#kapipy.items.TableItem.query_json(cql_filter)","title":"<code>cql_filter</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The CQL filter to apply to the query.</p>"},{"location":"reference/#kapipy.items.TableItem.query_json(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>Additional parameters for the WFS query.</p>"},{"location":"reference/#kapipy.job_result.JobResult","title":"JobResult","text":"<pre><code>JobResult(\n    payload: dict,\n    gis: GIS,\n    poll_interval: int = None,\n    timeout: int = None,\n)\n</code></pre> <p>Represents the result of an asynchronous export or processing job.</p> <p>Provides methods to poll for job completion, retrieve job status, and download results. The download and download_async methods return a DownloadResult object containing detailed metadata about the downloaded file. Download metadata is also stored as attributes on the JobResult instance after a successful download.</p> <p>Attributes:</p> <ul> <li> <code>_initial_payload</code>               (<code>dict</code>)           \u2013            <p>The initial job payload from the API.</p> </li> <li> <code>_job_url</code>               (<code>str</code>)           \u2013            <p>The URL to poll for job status.</p> </li> <li> <code>_id</code>               (<code>int</code>)           \u2013            <p>The unique identifier of the job.</p> </li> <li> <code>_poll_interval</code>               (<code>int</code>)           \u2013            <p>Polling interval in seconds.</p> </li> <li> <code>_timeout</code>               (<code>int</code>)           \u2013            <p>Maximum time to wait for job completion in seconds.</p> </li> <li> <code>_last_response</code>               (<code>dict</code>)           \u2013            <p>The most recent job status response.</p> </li> <li> <code>_gis</code>               (<code>GIS</code>)           \u2013            <p>The GIS instance associated with this job.</p> </li> <li> <code>#</code>               (<code>Populated after download</code>)           \u2013            </li> <li> <code>download_folder</code>               (<code>str</code>)           \u2013            <p>The directory where the file was saved.</p> </li> <li> <code>download_filename</code>               (<code>str</code>)           \u2013            <p>The name of the downloaded file.</p> </li> <li> <code>download_file_path</code>               (<code>str</code>)           \u2013            <p>The full path to the downloaded file.</p> </li> <li> <code>download_file_size_bytes</code>               (<code>int</code>)           \u2013            <p>The size of the downloaded file in bytes.</p> </li> <li> <code>download_completed_at</code>               (<code>float</code>)           \u2013            <p>The timestamp when the download completed.</p> </li> <li> <code>download_resolved_url</code>               (<code>str</code>)           \u2013            <p>The final resolved URL after redirects.</p> </li> <li> <code>download_checksum</code>               (<code>str | None</code>)           \u2013            <p>The SHA256 checksum of the downloaded file.</p> </li> </ul> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> <li> </li> </ul> <p>Methods:</p> <ul> <li> <code>download</code>             \u2013              <p>Waits for the job to finish, then downloads the file synchronously.</p> </li> <li> <code>output</code>             \u2013              <p>Blocks until the job completes, then returns the final job response.</p> </li> <li> <code>to_dict</code>             \u2013              <p>Returns the most recent job status response as a dictionary.</p> </li> </ul>"},{"location":"reference/#kapipy.job_result.JobResult(payload)","title":"<code>payload</code>","text":"(<code>dict</code>)           \u2013            <p>The job payload, typically from an API response.</p>"},{"location":"reference/#kapipy.job_result.JobResult(gis)","title":"<code>gis</code>","text":"(<code>GIS</code>)           \u2013            <p>The GIS instance associated with this job.</p>"},{"location":"reference/#kapipy.job_result.JobResult(poll_interval)","title":"<code>poll_interval</code>","text":"(<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Interval in seconds to poll the job status. Default is 10.</p>"},{"location":"reference/#kapipy.job_result.JobResult(timeout)","title":"<code>timeout</code>","text":"(<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Maximum time in seconds to wait for the job to complete. Default is 600.</p>"},{"location":"reference/#kapipy.job_result.JobResult.created_at","title":"created_at  <code>property</code>","text":"<pre><code>created_at: str | None\n</code></pre> <p>Returns the creation time of the job.</p> <p>Returns:</p> <ul> <li> <code>str | None</code>           \u2013            <p>str | None: The creation timestamp, or None if not available.</p> </li> </ul>"},{"location":"reference/#kapipy.job_result.JobResult.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>Returns the name of the job.</p>"},{"location":"reference/#kapipy.job_result.JobResult.progress","title":"progress  <code>property</code>","text":"<pre><code>progress: float | None\n</code></pre> <p>Returns the progress of the job as a percentage.</p> <p>Returns:</p> <ul> <li> <code>float | None</code>           \u2013            <p>float | None: The progress value, or None if not available.</p> </li> </ul>"},{"location":"reference/#kapipy.job_result.JobResult.state","title":"state  <code>property</code>","text":"<pre><code>state: str\n</code></pre> <p>Returns the current state of the job.</p> <p>Returns:</p> <ul> <li> <code>str</code> (              <code>str</code> )          \u2013            <p>The job state. Possible values include 'complete', 'processing', 'cancelled', 'error', 'gone'.</p> </li> </ul>"},{"location":"reference/#kapipy.job_result.JobResult.status","title":"status  <code>property</code>","text":"<pre><code>status: JobStatus\n</code></pre> <p>Refreshes and returns the current job status.</p> <p>Returns:</p> <ul> <li> <code>JobStatus</code> (              <code>JobStatus</code> )          \u2013            <p>The state and progress of the job.</p> </li> </ul>"},{"location":"reference/#kapipy.job_result.JobResult.download","title":"download","text":"<pre><code>download(\n    folder: str, file_name: str | None = None\n) -&gt; DownloadResult\n</code></pre> <p>Waits for the job to finish, then downloads the file synchronously.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DownloadResult</code> (              <code>DownloadResult</code> )          \u2013            <p>Object containing details about the downloaded file.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the download URL is not available.</p> </li> </ul>"},{"location":"reference/#kapipy.job_result.JobResult.download(folder)","title":"<code>folder</code>","text":"(<code>str</code>)           \u2013            <p>The folder where the file will be saved.</p>"},{"location":"reference/#kapipy.job_result.JobResult.download(file_name)","title":"<code>file_name</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The name of the file to save. If None, uses the job name.</p>"},{"location":"reference/#kapipy.job_result.JobResult.output","title":"output","text":"<pre><code>output() -&gt; dict\n</code></pre> <p>Blocks until the job completes, then returns the final job response.</p> <p>Returns:</p> <ul> <li> <code>dict</code> (              <code>dict</code> )          \u2013            <p>The final job response after completion.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TimeoutError</code>             \u2013            <p>If the job does not complete within the timeout.</p> </li> <li> <code>RuntimeError</code>             \u2013            <p>If the job fails or is cancelled.</p> </li> </ul>"},{"location":"reference/#kapipy.job_result.JobResult.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict\n</code></pre> <p>Returns the most recent job status response as a dictionary.</p> <p>Returns:</p> <ul> <li> <code>dict</code> (              <code>dict</code> )          \u2013            <p>The most recent job status response.</p> </li> </ul>"},{"location":"reference/#custom-errors","title":"Custom Errors","text":""},{"location":"reference/#kapipy.custom_errors","title":"custom_errors","text":"<p>custom_errors.py Custom exceptions.</p> <p>Classes:</p> <ul> <li> <code>BadRequest</code>           \u2013            <p>Exception raised for HTTP 400 Bad Request errors.</p> </li> <li> <code>ExportError</code>           \u2013            <p>Custom exception for errors encountered during export operations.</p> </li> <li> <code>HTTPError</code>           \u2013            <p>Base exception for HTTP errors.</p> </li> <li> <code>NotFound</code>           \u2013            <p>Exception raised for HTTP 404 Not Found errors.</p> </li> <li> <code>ServerError</code>           \u2013            <p>Exception raised for HTTP 500 Server Error errors.</p> </li> <li> <code>Unauthorized</code>           \u2013            <p>Exception raised for HTTP 401 Unauthorized errors.</p> </li> <li> <code>UnknownItemTypeError</code>           \u2013            <p>Exception raised when an unknown item type is encountered.</p> </li> </ul>"},{"location":"reference/#kapipy.custom_errors.BadRequest","title":"BadRequest","text":"<p>               Bases: <code>HTTPError</code></p> <p>Exception raised for HTTP 400 Bad Request errors.</p>"},{"location":"reference/#kapipy.custom_errors.ExportError","title":"ExportError","text":"<p>               Bases: <code>Exception</code></p> <p>Custom exception for errors encountered during export operations.</p>"},{"location":"reference/#kapipy.custom_errors.HTTPError","title":"HTTPError","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for HTTP errors.</p>"},{"location":"reference/#kapipy.custom_errors.NotFound","title":"NotFound","text":"<p>               Bases: <code>HTTPError</code></p> <p>Exception raised for HTTP 404 Not Found errors.</p>"},{"location":"reference/#kapipy.custom_errors.ServerError","title":"ServerError","text":"<p>               Bases: <code>HTTPError</code></p> <p>Exception raised for HTTP 500 Server Error errors.</p>"},{"location":"reference/#kapipy.custom_errors.Unauthorized","title":"Unauthorized","text":"<p>               Bases: <code>HTTPError</code></p> <p>Exception raised for HTTP 401 Unauthorized errors.</p>"},{"location":"reference/#kapipy.custom_errors.UnknownItemTypeError","title":"UnknownItemTypeError","text":"<pre><code>UnknownItemTypeError(message: str)\n</code></pre> <p>               Bases: <code>Exception</code></p> <p>Exception raised when an unknown item type is encountered.</p> <p>This exception is used to signal that an item kind is not supported by the client.</p> <p>Parameters:</p> <p>Attributes:</p> <ul> <li> <code>message</code>               (<code>str</code>)           \u2013            <p>Description of the error.</p> </li> </ul> <p>Parameters:</p> <ul> <li> </li> </ul>"},{"location":"reference/#kapipy.custom_errors.UnknownItemTypeError(message)","title":"<code>message</code>","text":"(<code>str</code>)           \u2013            <p>Description of the error.</p>"},{"location":"reference/#kapipy.custom_errors.UnknownItemTypeError(message)","title":"<code>message</code>","text":"(<code>str</code>)           \u2013            <p>Description of the error.</p>"},{"location":"usage/","title":"Usage Guide","text":"<p>This guide walks you through the main ways to use the <code>kapipy</code> package to query and download data from the LINZ Data Service via Koordinates.</p>"},{"location":"usage/#installation-notes","title":"Installation Notes","text":"<p>Kapipy is designed to use either GeoPandas or the ArcGIS API for Python, returning and reading data as either a GeoDataFrame or a Spatially Enabled DataFrame respectively.  Neither package is defined as a requirement of kapipy, as users may choose to use one over the other and may not want the other automatically installed.  </p> <p>This means you need to manually install one of either geopandas or arcgis into your Python environment.</p>"},{"location":"usage/#arcgis","title":"ArcGIS","text":"<p>If you are an ArcGIS user, cloning the default conda environment from ArcGIS Pro or ArcGIS Server should be sufficient, and you just need to install kapipy. If you choose to start with a blank environment and do not intend to install arcpy, you may need to install the following: - pyproj - shapely - pyshp  </p>"},{"location":"usage/#jupyter-notebooks","title":"Jupyter Notebooks","text":"<p>If you are starting with a clean Python environment and want to use Jupyter Notebooks (e.g. inside Visual Studio Code), then manually install these packages: - ipykernel - ptyprocess - comm  </p>"},{"location":"usage/#connecting-to-the-various-open-data-portals","title":"Connecting to the various open data portals","text":"<p>LINZ, Stats NZ and LRIS have built in names for convenience. Alternatively, pass in the base URL.  </p> <pre><code>from kapipy.gis import GIS\n\nlinz = GIS(name=\"linz\", api_key=\"your-linz-api-key\")\nstatsnz = GIS(name='statsnz', api_key=\"your-stats-api-key\")\nlris = GIS(name='lris', api_key=\"your-lris-api-key\")\n</code></pre> <p>Passing in a base url:  </p> <pre><code>from kapipy.gis import GIS\n\nlinz = GIS(url=\"https://data.linz.govt.nz/\", api_key=\"your-linz-api-key\")\n</code></pre>"},{"location":"usage/#get-a-reference-to-an-item","title":"Get a reference to an item","text":"<p>The gis object has a property called content which is a ContentManager. This allows you to get a reference to an item using it's id.  </p> <pre><code>from kapipy.gis import GIS\n\n#create gis object\nlinz = GIS(name=\"linz\", api_key=\"your-linz-api-key\")\n\n#get item object\nrail_station_layer_id = \"50318\" #rail station 175 points\nitm = linz.content.get(rail_station_layer_id)\n\nprint(itm)\n</code></pre>"},{"location":"usage/#wfs-queries","title":"WFS queries","text":"<p>Items with WFS endpoints can be queried using the query and get_changeset methods of the itm.</p> <p>For spatial items, it is recommended to provide a desired spatial reference via the out_sr parameter.  </p>"},{"location":"usage/#query","title":"Query","text":"<p>Get all data  </p> <pre><code>data = itm.query(out_sr=2193)\n</code></pre> <p>Get first 5 records.  </p> <pre><code>data = itm.query(count=5, out_sr=2193)\n</code></pre> <p>Spatial data is returned as either a geopandas GeoDataFrame or an ArcGIS Spatially Enabled DataFrame. The attribute types are set according to the item's field list. Tabular data is returned as a pandas DataFrame.  </p> <pre><code>print(data.dtypes())\nprint(data.head())\n</code></pre>"},{"location":"usage/#changeset","title":"Changeset","text":"<p>Also returned as a data frame with the same logic as the query method. The datetime parameters should be provided in ISO 8601 format.  </p> <p>The from_time parameter is the time from which the changeset data will be generated. The to_time parameter is optional, and is the time up to which the changeset data will be generated. If this parameter is not provided then it defaults to now.  </p> <pre><code>changeset = itm.get_changeset(from_time=\"2024-01-01T00:00:00Z\", out_sr=2193)\nprint((f\"Total records returned {itm.title}: {changeset.shape[0]}\"))\n</code></pre>"},{"location":"usage/#export-data","title":"Export data","text":"<p>Exporting data creates an asynchronous task on the data portal server that returns a job id. It is possible to create and manage individual downloads, or treat them collectively.  </p> <p>Again, it is recommended to always specify the out_sr.  </p>"},{"location":"usage/#single-item-export","title":"Single item export","text":"<p>The item export method initiates the creation of the job on the server and a JobResult object is returned. Accessing the status property triggers a check with the server to get the latest status of the job. The status returned is a JobStatus object that has state and progress properties.  </p> <pre><code>job = itm.export(\"geodatabase\", out_sr=2193)\nprint(job.status)\n</code></pre> <p>Download the job data once it is ready. If this method is called before the job state is 'complete', it will poll the status of the job until it is ready and then downloads it. Calling the download method of a JobResult object gives you the flexibility of specifying a specific folders for that download.</p> <pre><code>job.download(folder=r\"c:/temp\")\n</code></pre>"},{"location":"usage/#generate-an-export-with-extent-geometry","title":"Generate an export with extent geometry","text":"<p>The extent argument can be passed in as a gdf or an sdf.  </p> <pre><code># gdf\nmatamata_gdf = gpd.read_file(\"../examples/matamata_piako.shp\")\n# sdf\nmatamata_sdf = pd.DataFrame.spatial.from_featureclass(\"../examples/matamata_piako.shp\")\n\njob = itm.export(\"geodatabase\", out_sr=2193, extent=matamata_sdf,)\n</code></pre>"},{"location":"usage/#export-and-download-multiple-items","title":"Export and download multiple items","text":"<p>Whenever the export method of an item is called, the JobResult object is added to a list belonging to the ContentManager called jobs. </p> <p>The ContentManager has a download method as well. Calling this method and passing in a folder will download to that folder any jobs in the content manager's job list that are not already downloaded.  </p> <pre><code>itm1.export(\"geodatabase\", out_sr=2193, extent=matamata_sdf,)\nitm2.export(\"geodatabase\", out_sr=2193, extent=matamata_sdf,)\n\nlinz.content.download(folder=r\"c:/temp\")\n</code></pre> <p>The ContentManager also has an output_folder property. You can set this and it will be used as the default if no folder is provided.  </p> <pre><code>linz.content.download_folder = r\"c:/temp\"\n\nitm1.export(\"geodatabase\", out_sr=2193, extent=matamata_sdf,)\nitm2.export(\"geodatabase\", out_sr=2193, extent=matamata_sdf,)\n\nlinz.content.download()\n</code></pre> <p>Alternatively, you can pass the content manager's download method a list of specific jobs and only those jobs will be downloaded.  </p> <pre><code>job_1 = itm1.export(\"geodatabase\", out_sr=2193, extent=matamata_sdf,)\njob_2 = itm2.export(\"geodatabase\", out_sr=2193, extent=matamata_sdf,)\njob_3 = itm3.export(\"geodatabase\", out_sr=2193, extent=matamata_sdf,)\njob_4 = itm4.export(\"geodatabase\", out_sr=2193, extent=matamata_sdf,)\njob_5 = itm5.export(\"geodatabase\", out_sr=2193, extent=matamata_sdf,)\n\n# only jobs 1, 3 and 5 will be downloaded\nlinz.content.download([job_1, job_3, job_5])\n</code></pre> <p>Once a job is downloaded, it's \"downloaded\" attribute will be set to True, and any future calls to the ContentManager's download method will not download it. Use the 'force_all' parameter to force a download of all jobs in the list, regardless of their download status.  </p> <pre><code>linz.content.download(force_all=True)\n</code></pre>"}]}